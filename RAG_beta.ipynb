{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecee2ca-aea4-406c-ba5d-54a4c294e98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arXiv_rag as ar # local file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c764064-b002-4e7f-8423-65e8d265fce1",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation on arXiv Abstracts (`hep-ph`)\n",
    "\n",
    "This notebook demonstrates a simple RAG (Retrieval-Augmented Generation) system using abstracts from the [arXiv preprint server](https://arxiv.org).\n",
    "\n",
    "We:\n",
    "- Fetch recent abstracts from arXiv\n",
    "- Embed them using a transformer-based sentence encoder\n",
    "- Store and retrieve embeddings using FAISS\n",
    "- Use GPT to generate answers from retrieved context\n",
    "\n",
    "##  FAISS: Facebook AI Similarity Search\n",
    "\n",
    "FAISS (Facebook AI Similarity Search) is a high-performance library for **efficient similarity search** over dense vector representations. It is especially well-suited for applications like retrieval-augmented generation (RAG), recommendation systems, and nearest-neighbor search in embedding spaces.  \n",
    "\n",
    "###  How It Works:\n",
    "- FAISS stores all of our abstract embeddings as vectors in a **vector index**.\n",
    "- When a user enters a query, we embed it using the same model (`all-MiniLM-L6-v2`).\n",
    "- FAISS compares the query vector to the stored vectors and returns the **top-k most similar** entries based on distance (usually L2 or cosine).\n",
    "\n",
    "###  Why We Use FAISS:\n",
    "- **Speed**: Handles millions of vectors efficiently with GPU/CPU support.\n",
    "- **Scalability**: Works well for large-scale document search.\n",
    "- **Simplicity**: Easy to use for exact or approximate nearest neighbor search.\n",
    "\n",
    "###  In This Project:\n",
    "- We use `IndexFlatL2` (a brute-force exact search index using Euclidean distance).\n",
    "- Abstracts are embedded once and stored.\n",
    "- At query time, FAISS retrieves the most semantically similar papers in milliseconds.\n",
    "\n",
    "This allows us to build a fast and responsive retrieval system that scales with more data.  Please visit [their gitub](https://github.com/facebookresearch/faiss/wiki/) for more info.\n",
    "\n",
    "\n",
    "##  Model Overview: `all-MiniLM-L6-v2`\n",
    "\n",
    "We use the `all-MiniLM-L6-v2` model from the [SentenceTransformers](https://www.sbert.net/) library to convert text into dense vector embeddings. These embeddings represent the **semantic meaning** of text and are used for similarity search in our RAG system.\n",
    "\n",
    "###  Key Features:\n",
    "- **Architecture**: MiniLM (6 Transformer layers, distilled from BERT)\n",
    "- **Embedding Dimension**: 384\n",
    "- **Speed**: Extremely fast, making it suitable for real-time or large-scale applications\n",
    "- **Use Case**: Optimized for general-purpose semantic similarity tasks (e.g., question answering, duplicate detection, clustering)\n",
    "\n",
    "###  Why We Use It:\n",
    "- Lightweight and fast — ideal for prototyping and scalable applications\n",
    "- High-quality embeddings despite small size\n",
    "- Pretrained on a diverse set of tasks like Natural Language Inference (NLI) and Semantic Textual Similarity (STS)\n",
    "\n",
    "###  Output:\n",
    "Each input text (e.g., an arXiv abstract or a user query) is mapped to a 384-dimensional vector that can be compared to other vectors using cosine or Euclidean distance.\n",
    "\n",
    "This model is especially useful for identifying semantically similar scientific texts, even when exact keywords don’t match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15185675-9a0b-4846-bf94-7d6127f499fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_and_embed_abstracts = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33af1c0b-54a1-44a7-916e-ab7362017c67",
   "metadata": {},
   "source": [
    "## Step 1: Fetch Recent arXiv Abstracts\n",
    "\n",
    "The function fetch_arxiv_abstracts() uses the official arXiv API to fetch recent papers in the `hep-ph` category. \n",
    "We store the title, abstract, arXiv ID, and PDF link for each paper.\n",
    "\n",
    "## Step 2: Embed Abstracts into Semantic Vectors\n",
    "\n",
    "We use `sentence-transformers` with the model `all-MiniLM-L6-v2` to convert each abstract into an embedding vector. These embeddings capture the semantic meaning of each paper.\n",
    "\n",
    "## Step 3: Store Embeddings in a FAISS Index\n",
    "\n",
    "We store the embeddings in a FAISS index for efficient similarity search. Metadata (like titles and abstracts) is saved separately in a JSON file.\n",
    "\n",
    "If you want to skip this step, set `fetch_and_embed_abstracts` to `False`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9be6b2-108a-45da-a744-88ca2ca14462",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fetch_and_embed_abstracts:\n",
    "    papers = ar.fetch_arxiv_abstracts(query=\"hep-ph\", max_results=500)\n",
    "    embeddings = ar.embed_abstracts(papers, show_progress_bar = False)\n",
    "    ar.store_faiss_index(embeddings, papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26f2c29-7f12-4d70-9ea6-3388cecebd22",
   "metadata": {},
   "source": [
    "## Step 4: Retrieve Similar Abstracts\n",
    "\n",
    "Given a user query, we embed it and use FAISS to retrieve the most semantically similar abstracts. These are the most relevant papers to the question being asked.  The default it to return the abstracts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9a1f10-c9cf-4b54-a2b4-de87a87814b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = input(\"Ask a physics question.  I will return papers with abstracts for you to read: \")\n",
    "ppr = ar.retrieve_similar_abstracts(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57901086-b305-44e0-811a-586f4e852a0e",
   "metadata": {},
   "source": [
    "### You can also return just the list of paper titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6e9a1d-2031-4219-9ba9-9e4edc973743",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = input(\"This query will provide a list of titles. Please ask your question: \")\n",
    "ppr = ar.retrieve_similar_abstracts(query, include_abstract = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ba8479-69c3-4a22-88e1-99dbdbfdd3d6",
   "metadata": {},
   "source": [
    "## More to come...\n",
    "\n",
    "This is really all there is to setting up a RAG functionality using an API for a data source and a basic sentence transformer.  Our next step will be to set up some tokens so that we can feed this into ChatGPT to make it a little more user friendly!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
