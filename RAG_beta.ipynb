{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ecee2ca-aea4-406c-ba5d-54a4c294e98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arXiv_rag as ar # local file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9fbf2f3-94b2-4469-a054-6e73325fe609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d66d8ed-67dd-415a-8b35-dd353f117082",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "ping_client = False\n",
    "#ping_client = True\n",
    "\n",
    "if ping_client:\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        print(\"âœ… Success! Response:\")\n",
    "        print(response.choices[0].message.content)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c764064-b002-4e7f-8423-65e8d265fce1",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation on arXiv Abstracts (`hep-ph`)\n",
    "\n",
    "This notebook demonstrates a simple RAG (Retrieval-Augmented Generation) system using abstracts from the [arXiv preprint server](https://arxiv.org).\n",
    "\n",
    "We:\n",
    "- Fetch recent abstracts from arXiv\n",
    "- Embed them using a transformer-based sentence encoder\n",
    "- Store and retrieve embeddings using FAISS\n",
    "- Use GPT to generate answers from retrieved context\n",
    "\n",
    "##  FAISS: Facebook AI Similarity Search\n",
    "\n",
    "FAISS (Facebook AI Similarity Search) is a high-performance library for **efficient similarity search** over dense vector representations. It is especially well-suited for applications like retrieval-augmented generation (RAG), recommendation systems, and nearest-neighbor search in embedding spaces.  \n",
    "\n",
    "###  How It Works:\n",
    "- FAISS stores all of our abstract embeddings as vectors in a **vector index**.\n",
    "- When a user enters a query, we embed it using the same model (`all-MiniLM-L6-v2`).\n",
    "- FAISS compares the query vector to the stored vectors and returns the **top-k most similar** entries based on distance (usually L2 or cosine).\n",
    "\n",
    "###  Why We Use FAISS:\n",
    "- **Speed**: Handles millions of vectors efficiently with GPU/CPU support.\n",
    "- **Scalability**: Works well for large-scale document search.\n",
    "- **Simplicity**: Easy to use for exact or approximate nearest neighbor search.\n",
    "\n",
    "###  In This Project:\n",
    "- We use `IndexFlatL2` (a brute-force exact search index using Euclidean distance).\n",
    "- Abstracts are embedded once and stored.\n",
    "- At query time, FAISS retrieves the most semantically similar papers in milliseconds.\n",
    "\n",
    "This allows us to build a fast and responsive retrieval system that scales with more data.  Please visit [their gitub](https://github.com/facebookresearch/faiss/wiki/) for more info.\n",
    "\n",
    "\n",
    "##  Model Overview: `all-MiniLM-L6-v2`\n",
    "\n",
    "We use the `all-MiniLM-L6-v2` model from the [SentenceTransformers](https://www.sbert.net/) library to convert text into dense vector embeddings. These embeddings represent the **semantic meaning** of text and are used for similarity search in our RAG system.\n",
    "\n",
    "###  Key Features:\n",
    "- **Architecture**: MiniLM (6 Transformer layers, distilled from BERT)\n",
    "- **Embedding Dimension**: 384\n",
    "- **Speed**: Extremely fast, making it suitable for real-time or large-scale applications\n",
    "- **Use Case**: Optimized for general-purpose semantic similarity tasks (e.g., question answering, duplicate detection, clustering)\n",
    "\n",
    "###  Why We Use It:\n",
    "- Lightweight and fast â€” ideal for prototyping and scalable applications\n",
    "- High-quality embeddings despite small size\n",
    "- Pretrained on a diverse set of tasks like Natural Language Inference (NLI) and Semantic Textual Similarity (STS)\n",
    "\n",
    "###  Output:\n",
    "Each input text (e.g., an arXiv abstract or a user query) is mapped to a 384-dimensional vector that can be compared to other vectors using cosine or Euclidean distance.\n",
    "\n",
    "This model is especially useful for identifying semantically similar scientific texts, even when exact keywords donâ€™t match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15185675-9a0b-4846-bf94-7d6127f499fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_and_embed_abstracts = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33af1c0b-54a1-44a7-916e-ab7362017c67",
   "metadata": {},
   "source": [
    "## Step 1: Fetch Recent arXiv Abstracts\n",
    "\n",
    "The function fetch_arxiv_abstracts() uses the official arXiv API to fetch recent papers in the `hep-ph` category. \n",
    "We store the title, abstract, arXiv ID, and PDF link for each paper.\n",
    "\n",
    "## Step 2: Embed Abstracts into Semantic Vectors\n",
    "\n",
    "We use `sentence-transformers` with the model `all-MiniLM-L6-v2` to convert each abstract into an embedding vector. These embeddings capture the semantic meaning of each paper.\n",
    "\n",
    "## Step 3: Store Embeddings in a FAISS Index\n",
    "\n",
    "We store the embeddings in a FAISS index for efficient similarity search. Metadata (like titles and abstracts) is saved separately in a JSON file.\n",
    "\n",
    "If you want to skip this step, set `fetch_and_embed_abstracts` to `False`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc9be6b2-108a-45da-a744-88ca2ca14462",
   "metadata": {},
   "outputs": [],
   "source": [
    "if fetch_and_embed_abstracts:\n",
    "    papers = ar.fetch_arxiv_abstracts(query=\"hep-ph\", max_results=500)\n",
    "    embeddings = ar.embed_abstracts(papers, show_progress_bar = False)\n",
    "    ar.store_faiss_index(embeddings, papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26f2c29-7f12-4d70-9ea6-3388cecebd22",
   "metadata": {},
   "source": [
    "## Step 4: Retrieve Similar Abstracts\n",
    "\n",
    "Given a user query, we embed it and use FAISS to retrieve the most semantically similar abstracts. These are the most relevant papers to the question being asked.  The default it to return the abstracts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e9a1f10-c9cf-4b54-a2b4-de87a87814b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask a physics question.  I will return papers with abstracts for you to read:  Higgs Bosons\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Matching Abstracts:\n",
      "\n",
      "--- [1] Searching for charged Higgs bosons via $e^+ e^- \\to H^\\pm W^\\mp S$ at the ILC ---\n",
      " Abstract: We investigate the phenomenology of the charged Higgs boson at the\n",
      "International Linear Collider (ILC) within the framework of the type-X\n",
      "Two-Higgs Doublet Model (2HDM), where a light charged Higgs boson, with a mass\n",
      "around 200 GeV or even smaller than top quark mass, is still being consistent\n",
      "with flavor physics data as well as with the colliders experimental data. In\n",
      "the theoretically and experimentally allowed parameter space, the $e^+ e^- \\to\n",
      "H^\\pm W^\\mp S$ (with $S = H, A$) production processes can yield signatures with\n",
      "event rates larger than those from $e^+ e^- \\to H^+ H^-$ and offer sensitivity\n",
      "to the Higgs mixing parameter $\\sin(\\beta-\\alpha)$. We consider the bosonic\n",
      "$H^\\pm \\to W^\\pm S$ decays, where the neutral scalar $S$ further decays into a\n",
      "pair of tau leptons. We show, through a detector-level Monte Carlo analysis,\n",
      "that the resulting $[\\tau\\tau][\\tau\\tau] WW$ final state could be seen at the\n",
      "ILC with at least 500 GeV center-of-mass energy and 500 fb$^{-1}$ of\n",
      "luminosity.\n",
      "\n",
      " arXiv link: http://arxiv.org/pdf/2506.01554v1\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "--- [2] A new probe of the quartic Higgs self-coupling ---\n",
      " Abstract: We calculate the corrections to the Higgs wave-function renormalization\n",
      "constant arising from modified cubic, quartic, and quintic Higgs self-couplings\n",
      "up to the two-loop level. Using our analytic results, we derive two-dimensional\n",
      "constraints on the modifications of the considered Higgs self-interactions that\n",
      "could potentially be set from precision measurements of single-Higgs production\n",
      "processes at the high-luminosity Large Hadron Collider (LHC) and a Future\n",
      "Circular Collider. Our novel constraints are compared to those that might be\n",
      "set by searches for multi-Higgs production at the same facilities. In view of\n",
      "the first LHC results on triple-Higgs production, we also review the current\n",
      "status of Higgs self-coupling determinations after LHC Run 2.\n",
      "\n",
      " arXiv link: http://arxiv.org/pdf/2505.20463v1\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
      "--- [3] Loop-corrected Trilinear Higgs Self-Couplings in the NMSSM with Inverse Seesaw Mechanism ---\n",
      " Abstract: The higher-order corrections for the SM-like Higgs boson mass and the\n",
      "trilinear Higgs self-couplings in the Next-to-Minimal Supersymmetric extension\n",
      "of the Standard Model (NMSSM) with Inverse Seesaw Mechanism are significant and\n",
      "highly correlated. We present here the full one-loop corrections to the\n",
      "trilinear Higgs self-couplings supplemented by the dominant top-Yukawa and\n",
      "strong coupling induced two-loop corrections from our previous calculations in\n",
      "the complex NMSSM. These corrections are performed consistently with the\n",
      "corresponding Higgs boson mass corrections. We discuss in detail the new\n",
      "effects from the extended neutrino and sneutrino sectors on both the trilinear\n",
      "Higgs self-couplings and the SM-like Higgs boson mass. When compared to the\n",
      "case of the NMSSM without Inverse Seesaw Mechanism, the new effects can be up\n",
      "to 10\\% for the effective SM-like trilinear Higgs self-couplings, and up to\n",
      "4.5\\% for the SM-like Higgs boson mass for valid parameter points, i.e. points\n",
      "satisfying the Higgs data, the neutrino data, the constraints from the charged\n",
      "lepton flavor-violating decays, and the new physics constraints from the\n",
      "oblique parameters $S, T, U$. The new corrections are also included in the\n",
      "Higgs-to-Higgs decays for the heavy Higgs states and implemented in the new\n",
      "version of the Fortran code NMSSMCALC-nuSS.\n",
      "\n",
      " arXiv link: http://arxiv.org/pdf/2506.02743v1\n",
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Ask a physics question.  I will return papers with abstracts for you to read: \")\n",
    "ppr = ar.retrieve_similar_abstracts(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57901086-b305-44e0-811a-586f4e852a0e",
   "metadata": {},
   "source": [
    "### You can also return just the list of paper titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6e9a1d-2031-4219-9ba9-9e4edc973743",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = input(\"This query will provide a list of titles. Please ask your question: \")\n",
    "ppr_titles = ar.retrieve_similar_abstracts(query, include_abstract = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990d3740-7ec5-4387-95fc-fda1ca75cd19",
   "metadata": {},
   "source": [
    "## Step 5:  Adding a generative AI componment\n",
    "\n",
    "For this you are going to need to add your API key to .env and make sure you have tokens:\n",
    "```python\n",
    "OPENAI_API_KEY=sk-proj-cy...\n",
    "``` \n",
    "\n",
    "### Model Overview: GPT-4o\n",
    "\n",
    "**GPT-4o** (\"o\" for *omni*) is OpenAI's most advanced and versatile model as of 2024. It is optimized for **multimodal reasoning**, supporting text, vision, and audio inputs (though this notebook uses text-only).\n",
    "\n",
    "Key characteristics:\n",
    "\n",
    "-  **High Accuracy**: Comparable to GPT-4-turbo in reasoning tasks, with improved response coherence and factuality.\n",
    "-  **Faster & Cheaper**: Lower latency and cost per token compared to GPT-4-turbo, making it suitable for interactive applications.\n",
    "-  **Context-Aware**: Supports longer context windows (up to 128k tokens).\n",
    "-  **Chat-Optimized**: Built for chat-style usage, with conversational memory and role-awareness.\n",
    "\n",
    "In this notebook, GPT-4o is used to **synthesize answers** from a set of retrieved arXiv abstracts. The model is provided with relevant context and prompted to generate expert-level answers to user queries.\n",
    "\n",
    "API Pricing:\n",
    "\n",
    "-  Input: \\$0.005 per 1,000 tokens  \n",
    "-  Output: \\$0.015 per 1,000 tokens  \n",
    "\n",
    "[Token estimator tool](https://platform.openai.com/tokenizer)\n",
    "\n",
    "#### Asking GPT-4o Questions About Retrieved arXiv Abstracts\n",
    "\n",
    "This cell demonstrates how to use OpenAI's GPT-4o model to analyze and answer questions based on a set of retrieved arXiv paper abstracts. \n",
    "\n",
    "The workflow is as follows:\n",
    "\n",
    "1. **Retrieve Relevant Abstracts**  \n",
    "   We use the `retrieve_similar_abstracts()` function to get the top-k papers related to a given query. These papers include metadata such as title and abstract.\n",
    "\n",
    "2. **Formulate a Research Question**  \n",
    "   The user provides a natural language question they'd like to answer using the context of the retrieved papers.\n",
    "\n",
    "3. **Query GPT-4o via API**  \n",
    "   The function `ask_question_about_abstracts()`:\n",
    "   - Concatenates all titles and abstracts into a single context string\n",
    "   - Builds a structured prompt with this context plus the user's question\n",
    "   - Sends it to the GPT-4o model via the OpenAI API\n",
    "   - Returns a concise and informed answer grounded in the abstract content\n",
    "\n",
    "This enables a form of lightweight, domain-specific retrieval-augmented generation (RAG) using just the OpenAI API and local FAISS-based retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6ccf6b5-6353-464f-a3ec-707a71a1ad0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ğŸ§  GPT-4o's Answer:\n",
       "\n",
       "Recent research on the Higgs boson is focused on several key areas:\n",
       "\n",
       "1. **Charged Higgs Bosons**: Studies are being conducted at the International Linear Collider (ILC) to explore the phenomenology of charged Higgs bosons within the type-X Two-Higgs Doublet Model (2HDM). This involves investigating production processes like $e^+ e^- \\to H^\\pm W^\\mp S$ and analyzing decay channels to detect potential signatures of charged Higgs bosons, particularly those lighter than the top quark.\n",
       "\n",
       "2. **Higgs Self-Couplings**: Researchers are calculating corrections to the Higgs wave-function renormalization constant due to modified cubic, quartic, and quintic Higgs self-couplings up to the two-loop level. These calculations aim to set constraints on Higgs self-interactions through precision measurements at the high-luminosity LHC and future colliders, enhancing our understanding of Higgs boson interactions.\n",
       "\n",
       "3. **New Physics Searches**: The Circular Electron-Positron Collider (CEPC) is proposed as a next-generation Higgs factory, offering opportunities to explore physics beyond the Standard Model. It aims to conduct precision measurements and searches for new physics, including exotic decays of the Higgs, dark matter phenomena, and electroweak phase transition studies. The CEPC's capabilities are expected to significantly advance the exploration of fundamental particle physics in the post-Higgs discovery era.\n",
       "\n",
       "Overall, the focus is on understanding the properties and interactions of the Higgs boson, searching for new physics, and testing theoretical models that extend beyond the Standard Model."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = ar.ask_question_about_abstracts(ppr, \"What is going on with the Higgs Boson these days?\")\n",
    "#print(\"GPT-4o's Answer:\\n\", answer)\n",
    "answer = ar.format_for_markdown(answer)\n",
    "display(Markdown(f\"### GPT-4o's Answer:\\n\\n{answer}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
